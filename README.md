# nvidia tensorRT contest demo

This project is designed to leverage cutting-edge technology in artificial intelligence (AI) to provide high-performance image and video inference, as well as generative AI for text chat. At its core, the backend engine utilizes Python and integrates Nvidia's TensorRT technology, enhancing efficiency and speed to meet the demands of real-time processing.

# DIAGRAM


Backend Engine: Developed in Python, the backend engine is the powerhouse of the project. It employs Nvidia TensorRT, a high-performance deep learning inference platform.
Frontend Interface: To ensure a user-friendly experience, the frontend is built with Angular. This modern framework provides a responsive and intuitive interface.
Middleware Layer: Bridging the frontend and the backend, the middleware layer is implemented using Spring Boot with Java. This component is crucial for orchestrating command-line commands to the Python-based AI engine.


# IA BACKGROUND

This project used as pretrained models for videio and image inference from pytorch Resnet18, also pretreained model distilbert-base-uncased-distilled-squad
for a generative IA chat bot based on Question-and-Answer system, these projects have been optimizing by using Nvidia's TensorRT technology; you can check the section (Compile section) how to compile onnx files and tensorRT engines.


# Models use for video and image inference (onnx and TensorRT engine files)

Model: Resnet18

# Models use for generative IA chat bot based on Question-and-Answer system (onnx and TensorRT engine files)

Model: distilbert-base-uncased-distilled-squad


# Compile section

asdas
asdas

asda

# Installation Guide

# Opcion one full installation



# Opcion two only uses python IA programs from a cmd console



# Gernal Resources


# Demo video

